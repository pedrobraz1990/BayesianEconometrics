{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Linear Regression Model\n",
    "\n",
    "## Likelihood Function\n",
    "\n",
    "$$ y_i = x^\\intercal_i \\beta + \\epsilon_i, \\qquad i=1,...,n$$\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "$\\epsilon_i \\sim^{iid} N(0,\\sigma^2)$\n",
    "\n",
    "$x_i$ is either fixed (not random) or it is independent of $\\epsilon_i$\n",
    "\n",
    "Assumptions imply: $f(y,x|\\beta,\\sigma^2) = f(y|x,\\beta,\\sigma^2)f(x|\\Lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our interest would be on $f(y,x|\\beta,\\sigma^2)$, since the above, we can disregard the marginal distribution of x and work with the conditional likelihood of each observation:\n",
    "\n",
    "$$f(y|x,\\beta,\\sigma^2) \\sim N((y_i-x_i\\beta),\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the disturbances are independent, the likelihood of the sample is given by:\n",
    "\n",
    "$$f(y|x,\\beta,\\sigma^2) = \\prod^n_{i=1} f(y_i|x_i,\\beta,\\sigma^2)$$\n",
    "\n",
    "Using the pdf or a normal distribution:\n",
    "\n",
    "$$f(y|x,\\beta,\\sigma^2)  = \\frac{1}{(2\\pi)^{n/2}\\sigma^n)} exp(-\\frac{1}{2\\sigma^2}(y-X\\beta)^\\intercal(y-X\\beta)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the likelihood in terms of the OLS using $y-\\beta = y-X(\\beta-\\hat{\\beta})-X\\hat{\\beta}$ yields:\n",
    "\n",
    "$$f(y|x,\\beta,\\sigma^2)  = \\frac{1}{(2\\pi)^{n/2}\\sigma^{n-v})} exp(-\\frac{1}{2\\sigma^2}(\\beta-\\hat{\\beta})^\\intercal X^\\intercal X (\\beta-\\hat{\\beta})) \\frac{1}{\\sigma^v}exp(-\\frac{s^2v}{2 \\sigma^2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that our likelihood is a normal function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where\n",
    "\n",
    "$$\\hat{\\beta} = (X^\\intercal X)^{-1} X^\\intercal y$$\n",
    "\n",
    "$$ s^2 = \\frac{(y-X \\hat{\\beta})^\\intercal (y-X \\hat{\\beta}) }{v} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a prior\n",
    "\n",
    "We know from conjugate priors that if we choose a Normal-Inverse Gamma as a prior it'll yield another NIG as posterior. This comes from a rationale developed on the class slides. We will just skip to the final prior distribution. So that we postulate:\n",
    "\n",
    "$$(\\beta,\\sigma^2) \\sim NIG(\\underline{\\beta},\\underline{V},1 / \\underline{\\sigma^2}, \\underline{v})$$\n",
    "\n",
    "All the underlined constants are called **hyperparameters** and are parameters of the prior distribution. Not to be confused with hyperparameters from the posterior distribution.\n",
    "\n",
    "If we do not find the distribution we can use the slide steps to draw the data from IG and Normal distributions.\n",
    "\n",
    "Then a discussion about the parametrization of the Gamma distribution follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultant Posterior\n",
    "\n",
    "$$ (\\beta, \\sigma^2 | y,X) \\sim NIG(\\overline{\\beta},\\overline{V},1/\\overline{\\sigma^2},\\overline{v}) $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ \\overline{V} = (\\underline{V}^{-1} + X^\\intercal X)^{-1} $$ \n",
    "\n",
    "$$\\overline{\\beta} = \\overline{V} (\\underline{V}^{-1} \\underline{\\beta} + X^\\intercal X \\hat{\\beta}) $$\n",
    "\n",
    "$$\\overline{v} = \\underline{v} + n $$\n",
    "\n",
    "$$ \\overline{\\sigma}^2 = \\frac{1}{\\overline{v}} ( \\underline{v \\sigma^2} + (n - k) s^2 + ( \\hat{\\beta} - \\underline{\\beta})^\\intercal  (\\underline{V} + (X^\\intercal X)^{-1})^{-1}  (\\hat{\\beta} - \\beta)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "## Sample\n",
    "\n",
    "First we will generate a sample from the true \"population\" that comes from a $N(\\beta,1)$\n",
    "\n",
    "For the multivariate case $\\beta$ is $(k x 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta = [5,10] #betas\n",
    "n = 100 #sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = len(beta)\n",
    "\n",
    "beta = np.array(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to generate $X$. Which has to be generated independently of the error term. Thus we will draw random values from a standard normal distribution. $X$ is a matrix $(n,k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.standard_normal((n,k))\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "#rename the columns for conveniece\n",
    "cols = pd.DataFrame(data=list(range(0,data.shape[1])))\n",
    "data.columns = (\"x\" + cols.astype(str))[0].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to generate the $y$'s, from the $x$'s and a random disturbance who also follows a std normal.\n",
    "\n",
    "$$y = x\\beta + \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.461389</td>\n",
       "      <td>-0.672083</td>\n",
       "      <td>-7.938436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.298645</td>\n",
       "      <td>2.010507</td>\n",
       "      <td>27.091955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.873146</td>\n",
       "      <td>-0.396031</td>\n",
       "      <td>-0.816526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.643229</td>\n",
       "      <td>-0.941906</td>\n",
       "      <td>3.069911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.107706</td>\n",
       "      <td>-0.818080</td>\n",
       "      <td>-3.592053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1          y\n",
       "0 -0.461389 -0.672083  -7.938436\n",
       "1  1.298645  2.010507  27.091955\n",
       "2  0.873146 -0.396031  -0.816526\n",
       "3  2.643229 -0.941906   3.069911\n",
       "4  1.107706 -0.818080  -3.592053"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'] = data.dot(beta) + np.random.standard_normal((n))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior\n",
    "\n",
    "For our NIG prior we have to choose a $\\beta$ value, a $V0$ value, a $\\sigma^2$ and a $v$ value. Also $m$ is the confidence we have in the prior (inversely related to its variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "betaPrior = [5,10]\n",
    "m = 1\n",
    "\n",
    "prior = {'b0': np.array(betaPrior),\n",
    "         'V0': 0.05/m * np.identity(k),\n",
    "         'sigma2_0':1,\n",
    "         'v':m }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that: \n",
    "\n",
    "$$\\hat{\\beta} = (X^\\intercal X)^{-1} X^\\intercal y$$\n",
    "\n",
    "$$ s^2 = \\frac{(y-X \\hat{\\beta})^\\intercal (y-X \\hat{\\beta}) }{v} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2103624263883663"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.ix[:, data.columns != 'y']\n",
    "y = data['y']\n",
    "\n",
    "beta_hat = np.linalg.inv((x.T.dot(x))).dot(x.T).dot(y)\n",
    "\n",
    "s2 = (y-x.dot(beta_hat)).T.dot(y-x.dot(beta_hat)) / (n-k)\n",
    "\n",
    "\n",
    "# beta_hat\n",
    "# (n-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
